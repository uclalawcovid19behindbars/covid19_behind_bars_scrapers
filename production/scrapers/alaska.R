source("./R/generic_scraper.R")
source("./R/utilities.R")

alaska_check_date <- function(x, date = Sys.Date()){
    raw_page <- xml2::read_html(x)

    covid_sub_page <- raw_page %>%
        rvest::html_node(xpath = "//h2[text() = 'Monthly DOC COVID-19 Tracker']/..")
    
    site_date <- covid_sub_page %>%
        rvest::html_nodes("p") %>%
        rvest::html_text() %>%
        {.[str_detect(., "(?i)last updated")]} %>%
        str_split("(?i)last updated ") %>%
        unlist() %>%
        .[2] %>%
        str_replace_all("[^[:alnum:]]", " ") %>%
        str_squish() %>%
        lubridate::mdy()
    
    error_on_date(site_date, date)
}


alaska_pull <- function(x){
    xml2::read_html(x)
}

alaska_restruct <- function(x){
    
    tibble(
        Name = "State-Wide",
        Residents.Remand = x %>%
            rvest::html_node('#remand_div .tracker_count') %>%
            rvest::html_text() %>%
            parse_number(),
        Residents.Confirmed = x %>%
            rvest::html_node('#positive_div .tracker_count') %>%
            rvest::html_text() %>%
            parse_number(),
        Residents.Tadmin = x %>%
            rvest::html_node('#tested_div .tracker_count') %>%
            rvest::html_text() %>%
            parse_number(),
        Residents.Negative = x %>%
            rvest::html_node('#negative_div .tracker_count') %>%
            rvest::html_text() %>%
            parse_number(),
        Residents.Pending = x %>%
            rvest::html_node('#pending_div .tracker_count') %>%
            rvest::html_text() %>%
            parse_number(),
        Residents.Deaths = x %>%
            rvest::html_node('#deaths_div .tracker_count') %>%
            rvest::html_text() %>%
            parse_number()
        )
}

alaska_extract <- function(x){
    x %>%
        mutate(Residents.Confirmed = Residents.Confirmed + Residents.Remand) %>%
        select(-Residents.Remand)
}

#' Scraper class for general Alaska COVID data
#' 
#' @name alaska_scraper
#' @description Minimal html webscraping. Since scraping began website has
#' had minimal changes. Only publishes state-wide information and only for
#' residents. Data is updated weekly.
#' \describe{
#'   \item{Total Tests}{Cumulatiove tests administered.}
#'   \item{Negative Tests}{Cumulative negative results.}
#'   \item{Pending Results}{Currently pending.}
#'   \item{Remand Positives}{Positives cases not sure how different from below.}
#'   \item{General Population Psoitives}{Not sure on the distinction here.}
#' }

alaska_scraper <- R6Class(
    "alaska_scraper",
    inherit = generic_scraper,
    public = list(
        log = NULL,
        initialize = function(
            log,
            url = "https://doc.alaska.gov/covid-19",
            id = "alaska",
            type = "html",
            state = "AK",
            jurisdiction = "state",
            check_date = alaska_check_date,
            # pull the JSON data directly from the API
            pull_func = alaska_pull,
            # restructuring the data means pulling out the data portion of the json
            restruct_func = alaska_restruct,
            # Rename the columns to appropriate database names
            extract_func = alaska_extract){
            super$initialize(
                url = url, id = id, pull_func = pull_func, type = type,
                restruct_func = restruct_func, extract_func = extract_func,
                log = log, state = state, jurisdiction = jurisdiction,
                check_date = check_date)
        }
    )
)

if(sys.nframe() == 0){
    alaska <- alaska_scraper$new(log=FALSE)
    alaska$run_check_date()
    alaska$raw_data
    alaska$pull_raw()
    alaska$raw_data
    alaska$restruct_raw()
    alaska$restruct_data
    alaska$extract_from_raw()
    alaska$extract_data
    alaska$validate_extract()
    alaska$save_extract()
}

